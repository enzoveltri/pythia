{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSCGtu1YslCq"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.1.1\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import csv\n",
        "from transformers import Trainer, TrainingArguments, RobertaForSequenceClassification, RobertaTokenizer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUwCJfnD0r8k"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_RwiWWztpVP"
      },
      "outputs": [],
      "source": [
        "class FEVEROUSDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels, use_labels = True):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "        self.use_labels = use_labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.use_labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYjBm4qHtvFK"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    class_rep = classification_report(labels, preds, target_names= ['NOT ENOUGH INFO', 'SUPPORTS', 'REFUTES'], output_dict=True)\n",
        "    print(class_rep)\n",
        "    print(\"Acc: {}, Recall: {}, Precision: {}, F1: {}\".format(acc, recall, precision, f1))\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'class_rep': class_rep\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf-fQ4EoLcs7"
      },
      "outputs": [],
      "source": [
        "def datasetStats(sentences, labels, useAmbLabel=False):\n",
        "  stats = {0:0, 1:0, 2:0}\n",
        "  if useAmbLabel: stats = {0:0, 1:0, 2:0, 3:0}\n",
        "  for sentence, label in zip(sentences, labels):\n",
        "    counter = stats[label]\n",
        "    counter += 1\n",
        "    stats[label] = counter\n",
        "  return stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWncRwNsMqGe"
      },
      "outputs": [],
      "source": [
        "def readTSVFile(file):\n",
        "  texts = []\n",
        "  labels = []\n",
        "  labelToUse = 0 ## CONTRADICTING / NEI\n",
        "  if 'uniform_true' in file:\n",
        "    labelToUse = 1 ## SUPPORTS\n",
        "  if 'uniform_false' in file:\n",
        "    labelToUse = 2 ## REFUTES\n",
        "  with open(file) as fd:\n",
        "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
        "    for row in rd:\n",
        "      texts.append(row[0])\n",
        "      labels.append(labelToUse)\n",
        "  return texts, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GREZrr2-UWOW"
      },
      "outputs": [],
      "source": [
        "def printPredictions(text_test, labels_test, predictions, labelToFilter=None):\n",
        "  for text, label, prediction in zip(text_test ,labels_test, predictions):\n",
        "    if labelToFilter is not None:\n",
        "      if label == labelToFilter: print(text, label, prediction)\n",
        "    else:\n",
        "      print(text, label, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvW6-Guls92e"
      },
      "source": [
        "# FEVEROUS DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri2Vx5HRswLT"
      },
      "outputs": [],
      "source": [
        "def to_sentence(selectedData):\n",
        "  text = \"\"\n",
        "  for pos in range(0, len(selectedData)):\n",
        "    text += str(selectedData[pos]).strip()\n",
        "    if pos + 1 < len(selectedData):\n",
        "      text += \" ; \"\n",
        "    else:\n",
        "      text += \".\"\n",
        "  return text.strip()\n",
        "\n",
        "def to_feverous_input(claim, evidence, evidenceContext, title):\n",
        "    sequence = [claim]\n",
        "    sequence += [title]\n",
        "    sequence += [to_sentence(evidence)]\n",
        "    sequence += [to_sentence(evidenceContext)]\n",
        "    return ' </s> '.join(sequence)\n",
        "\n",
        "def toFeverousLabel(label):\n",
        "  labelToUse = 0 ## CONTRADICTING / NEI\n",
        "  if label == 'SUPPORTS':\n",
        "    labelToUse = 1 ## SUPPORTS\n",
        "  if label == 'REFUTES':\n",
        "    labelToUse = 2 ## REFUTES\n",
        "  return labelToUse\n",
        "\n",
        "\n",
        "BASE_PATH = \"MyDrive/feverous/feverousTest/\" ## path to the feverous folder. Available at: https://drive.google.com/drive/folders/1GCemGB3mADdHHQli41B9e0d3Brwn0lUx?usp=sharing\n",
        "fileTestFeverous = BASE_PATH+\"train_with_values.jsonl\"\n",
        "\n",
        "with open(fileTestFeverous, 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "\n",
        "count = 0\n",
        "countOK = 0\n",
        "sentences = []\n",
        "labels = []\n",
        "sentencesSet = set()\n",
        "for json_str in json_list:\n",
        "    #json_str = json_str.replace(\"\\'\", \"\\\"\")\n",
        "    try:\n",
        "      data = json.loads(json_str)\n",
        "      parsed = isinstance(data, dict)\n",
        "      if parsed:\n",
        "        count += 1\n",
        "        claim = data['claim']\n",
        "        label = data['label']\n",
        "        evidence = data['evidence']\n",
        "        evidenceContext = data['evidence_ctxt']\n",
        "        title = data['title']\n",
        "        if len(evidence) > 0 or len(evidenceContext) > 0:\n",
        "          #print(claim)\n",
        "          #print(label)\n",
        "          #print(evidence)\n",
        "          #print(evidenceContext)\n",
        "          #print(title)\n",
        "          text = to_feverous_input(claim, evidence, evidenceContext, title)\n",
        "          labelData = toFeverousLabel(label)\n",
        "          countOK += 1\n",
        "          sentences.append(text)\n",
        "          sentencesSet.add(text)\n",
        "          labels.append(labelData)\n",
        "    except:\n",
        "      pass\n",
        "      #traceback.print_exc()\n",
        "    \n",
        "print(\"Count: \", count)\n",
        "print(\"CountOK: \", countOK)\n",
        "#print(len(sentences), len(labels))\n",
        "\n",
        "stats = datasetStats(sentences, labels)\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AjJfhqkYTVi"
      },
      "source": [
        "## EXTRA NEIs from FEVEROUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaRhdg6DYRtH"
      },
      "outputs": [],
      "source": [
        "addExtraNEIsFromFEVEROUS = True ##load more NEI from FEVEROUS\n",
        "extraNEI = 100 ## number of extra NEI to add to the current dataset\n",
        "\n",
        "BASE_PATH = \"MyDrive/feverous/feverousTest/\" ## path to the feverous folder\n",
        "fileTestFeverous = BASE_PATH+\"train_with_values_NEI.jsonl\"\n",
        "\n",
        "with open(fileTestFeverous, 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "\n",
        "count = 0\n",
        "countOK = 0\n",
        "sentencesNEI = []\n",
        "labelsNEI = []\n",
        "for json_str in json_list:\n",
        "    #json_str = json_str.replace(\"\\'\", \"\\\"\")\n",
        "    try:\n",
        "      data = json.loads(json_str)\n",
        "      parsed = isinstance(data, dict)\n",
        "      if parsed:\n",
        "        count += 1\n",
        "        claim = data['claim']\n",
        "        label = data['label']\n",
        "        evidence = data['evidence']\n",
        "        evidenceContext = data['evidence_ctxt']\n",
        "        title = data['title']\n",
        "        if len(evidence) > 0 or len(evidenceContext) > 0:\n",
        "          #print(claim)\n",
        "          #print(label)\n",
        "          #print(evidence)\n",
        "          #print(evidenceContext)\n",
        "          #print(title)\n",
        "          text = to_feverous_input(claim, evidence, evidenceContext, title)\n",
        "          labelData = toFeverousLabel(label)\n",
        "          countOK += 1\n",
        "          sentencesNEI.append(text)\n",
        "          labelsNEI.append(labelData)\n",
        "    except:\n",
        "      pass\n",
        "      #traceback.print_exc()\n",
        "    \n",
        "print(\"Count: \", count)\n",
        "print(\"CountOK: \", countOK)\n",
        "\n",
        "stats = datasetStats(sentencesNEI, labelsNEI)\n",
        "print(stats)\n",
        "\n",
        "if addExtraNEIsFromFEVEROUS:\n",
        "  counterExtra = 0\n",
        "  for newSentence, newLabel in zip(sentencesNEI,labelsNEI):\n",
        "    if newSentence not in sentencesSet:\n",
        "      if counterExtra < extraNEI:\n",
        "        sentences.append(newSentence)\n",
        "        labels.append(newLabel)\n",
        "        counterExtra += 1\n",
        "  #sentences += sentencesNEI\n",
        "  #labels += labelsNEI\n",
        "  pairs = list(zip(sentences, labels))\n",
        "  random.Random(42).shuffle(pairs)\n",
        "  sentences, labels = zip(*pairs)\n",
        "\n",
        "stats = datasetStats(sentences, labels)\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7oLqBLutHv3"
      },
      "outputs": [],
      "source": [
        "text_train_feverous, text_test_feverous, labels_train_feverous, labels_test_feverous = train_test_split(sentences, labels, test_size=0.2, random_state=42, shuffle=True)\n",
        "print(datasetStats(text_train_feverous, labels_train_feverous))\n",
        "print(datasetStats(text_test_feverous, labels_test_feverous))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVgHm7Nm6e8j"
      },
      "outputs": [],
      "source": [
        "allNeiInTest = False ## set to true if you want to put all current NEI in the test set \n",
        "numberOfNeisToAddInTest = 30 ## control the number of NEI examples to add in test\n",
        "text_train_feverous_filtered = []\n",
        "labels_train_feverous_filtered = []\n",
        "if allNeiInTest:\n",
        "  for text, label in zip(text_train_feverous, labels_train_feverous):\n",
        "    if label == 0: ## NEI\n",
        "      text_test_feverous.append(text)\n",
        "      labels_test_feverous.append(label)\n",
        "    else:\n",
        "      text_train_feverous_filtered.append(text)\n",
        "      labels_train_feverous_filtered.append(label)\n",
        "  text_train_feverous = text_train_feverous_filtered\n",
        "  labels_train_feverous = labels_train_feverous_filtered\n",
        "\n",
        "print(len(text_train_feverous), len(labels_train_feverous))\n",
        "print(len(text_test_feverous), len(labels_test_feverous))\n",
        "\n",
        "print(datasetStats(text_train_feverous, labels_train_feverous))\n",
        "print(datasetStats(text_test_feverous, labels_test_feverous))\n",
        "\n",
        "if numberOfNeisToAddInTest is not None:\n",
        "  tmp_text = []\n",
        "  tmp_labels = []\n",
        "  counter = 0\n",
        "  for text, label in zip(text_test_feverous, labels_test_feverous):\n",
        "    if label == 0: ## NEI\n",
        "      if counter < numberOfNeisToAddInTest:\n",
        "        tmp_text.append(text)\n",
        "        tmp_labels.append(label)\n",
        "        counter += 1\n",
        "    else:\n",
        "      tmp_text.append(text)\n",
        "      tmp_labels.append(label)\n",
        "  text_test_feverous = tmp_text\n",
        "  labels_test_feverous = tmp_labels\n",
        "\n",
        "print(datasetStats(text_train_feverous, labels_train_feverous))\n",
        "print(datasetStats(text_test_feverous, labels_test_feverous)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ4hutKCtfi-"
      },
      "source": [
        "#BASELINE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-8ITDGAtcLS"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/gdrive/MyDrive/feverous/feverous_verdict_predictor.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSiCSa57tlPt"
      },
      "outputs": [],
      "source": [
        "def model_trainer(model_path, test_dataset):\n",
        "    # model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels =4)\n",
        "    model = RobertaForSequenceClassification.from_pretrained(model_path, num_labels =3, return_dict=True)\n",
        "\n",
        "    #anfs/bigdisc/rmya2/faiss_data/model_verdict_predictor/checkpoint-1500'\n",
        "    training_args = TrainingArguments(\n",
        "    output_dir='/content/results',          # output directory\n",
        "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    eval_dataset=test_dataset,          # evaluation dataset\n",
        "    compute_metrics = compute_metrics,\n",
        "    )\n",
        "    return trainer, model\n",
        "\n",
        "def claim_predictor(model_path, text_test_tokenized, labels_test):\n",
        "    ### args.model_path is the only required parameter\n",
        "    #tokenizer = RobertaTokenizer.from_pretrained('ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli')\n",
        "    #text_test_tokenized = tokenizer(text_test, padding=True, truncation=True)\n",
        "    test_dataset = FEVEROUSDataset(text_test_tokenized, labels_test)\n",
        "\n",
        "    trainer, model = model_trainer(model_path, test_dataset)\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    predictions = predictions.predictions.argmax(-1)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KylOd1D7t6oV"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH_LOCAL = '/content/feverous_verdict_predictor/'\n",
        "tokenizer = RobertaTokenizer.from_pretrained('ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli')\n",
        "text_test_tokenized = tokenizer(text_test_feverous, padding=True, truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO5O7qCsuEHd"
      },
      "outputs": [],
      "source": [
        "predictions = claim_predictor(MODEL_PATH_LOCAL, text_test_tokenized, labels_test_feverous)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkCCjWo1CERd"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mcrvVpy_V5k"
      },
      "outputs": [],
      "source": [
        "## PARAMS\n",
        "shuffleSentences = True\n",
        "nei_finetuning_size = 40\n",
        "addExtra = True  ## set to True to extend the current dataset with Pythia Templates Examples\n",
        "addTemplates = False  ## if true extends data with Pythia Templates examples\n",
        "\n",
        "BASE_PATH = \"MyDrive/feverous/feverousTest/\" ## path to the feverous folder\n",
        "FOLDER_PATH = BASE_PATH + \"fine-tuning/\"\n",
        "TEMPLATE_PATH = BASE_PATH + \"feverousTemplates/\"\n",
        "sentences, labels = loadData(FOLDER_PATH)\n",
        "\n",
        "nei_sentences = []\n",
        "nei_labels = []\n",
        "for sentence, label in zip(sentences, labels):\n",
        "  if label == 0:\n",
        "    nei_sentences.append(sentence)\n",
        "    nei_labels.append(label)\n",
        "\n",
        "nei_templates_sentences = []\n",
        "nei_templates_labels = []\n",
        "if addTemplates:\n",
        "  files = [f for f in listdir(TEMPLATE_PATH) if isfile(join(TEMPLATE_PATH, f))]\n",
        "  for file in files:\n",
        "    if \"contradicting\" in file:\n",
        "      fileToLoad = TEMPLATE_PATH + file\n",
        "      text, labels = readTSVFile(fileToLoad)\n",
        "      nei_templates_sentences += text\n",
        "      nei_templates_labels += labels\n",
        "  random.Random(42).shuffle(nei_templates_sentences)\n",
        "  nei_templates_sentences = nei_templates_sentences[0:nei_finetuning_size]\n",
        "  nei_templates_labels = nei_templates_labels[0:nei_finetuning_size]\n",
        "  nei_sentences = nei_sentences + nei_templates_sentences\n",
        "  nei_labels = nei_labels + nei_templates_labels\n",
        "\n",
        "if shuffleSentences:\n",
        "  random.Random(42).shuffle(nei_sentences)\n",
        "\n",
        "sentencesAdd = nei_sentences[0:nei_finetuning_size]\n",
        "labelAdd = nei_labels[0:nei_finetuning_size]\n",
        "\n",
        "extended_train_text = text_train_feverous\n",
        "extendend_train_labels = labels_train_feverous\n",
        "\n",
        "if addExtra:\n",
        "  extended_train_text = text_train_feverous + sentencesAdd\n",
        "  extendend_train_labels = labels_train_feverous + labelAdd\n",
        "  pairs = list(zip(extended_train_text, extendend_train_labels))\n",
        "  random.Random(42).shuffle(pairs)\n",
        "  extended_train_text, extendend_train_labels = zip(*pairs)\n",
        "\n",
        "print(len(extended_train_text))\n",
        "print(len(extendend_train_labels))\n",
        "\n",
        "print(datasetStats(extended_train_text, extendend_train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zNESmK1DUp0"
      },
      "outputs": [],
      "source": [
        "def finetune(model_path, train_dataset, test_dataset, epochs = 1):\n",
        "    model = RobertaForSequenceClassification.from_pretrained(model_path, num_labels =3, return_dict=True)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "    output_dir='/content/resultsFineTuning',          # output directory\n",
        "    num_train_epochs=epochs,              # total # of training epochs\n",
        "    per_device_train_batch_size=2,  # batch size per device during training (we used 2 to avoid memory errors)\n",
        "    per_device_eval_batch_size=1,   # batch size for evaluation\n",
        "    warmup_steps=0,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir= os.path.join(model_path, 'logs'),            # directory for storing logs\n",
        "    logging_steps=500,\n",
        "    save_steps = 5900, #1200,\n",
        "    learning_rate = 1e-05\n",
        "    # save_strategy='epoch'\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    compute_metrics = compute_metrics,\n",
        "    )\n",
        "    return trainer, model\n",
        "\n",
        "def finetune_claim_predictor(model_path, train_dataset, test_dataset, epochs=1):\n",
        "    trainer, model = finetune(model_path, train_dataset, test_dataset, epochs)\n",
        "    trainer.train()\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    predictions = predictions.predictions.argmax(-1)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsw3DEKxFnDA"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH_LOCAL = '/content/feverous_verdict_predictor/'\n",
        "text_train_tokenized = tokenizer(extended_train_text, padding=True, truncation=True)\n",
        "train_dataset = FEVEROUSDataset(text_train_tokenized, extendend_train_labels)\n",
        "test_dataset = FEVEROUSDataset(extended_text_test_tokenized, extended_labels_test_feverous)\n",
        "epochs = 3\n",
        "predictions = finetune_claim_predictor(MODEL_PATH_LOCAL, train_dataset, test_dataset, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJHAPhp4Uy7S"
      },
      "outputs": [],
      "source": [
        "printPredictions(extended_text_test_feverous, extended_labels_test_feverous, predictions, labelToFilter=0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Pythia-FEVEROUS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}