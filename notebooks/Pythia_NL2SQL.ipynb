{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPZ4aKESoV2d"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers\n",
        "#!pip install transformers==4.1.1\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install -q datasets sacrebleu\n",
        "\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from datasets import load_metric\n",
        "import random\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuHMGTIQod0h"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW_uAODxpD_A"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iAv6xRuohb_"
      },
      "outputs": [],
      "source": [
        "def get_sql(query):\n",
        "  input_text = \"translate English to SQL: %s </s>\" % query\n",
        "  features = tokenizer([input_text], return_tensors='pt')\n",
        "\n",
        "  output = model.generate(input_ids=features['input_ids'], \n",
        "               attention_mask=features['attention_mask'])\n",
        "  \n",
        "  return tokenizer.decode(output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRuSHc_uomZe"
      },
      "outputs": [],
      "source": [
        "query = \"messi has 12 cards\" ## red or yellow ?\n",
        "get_sql(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T-ZK0XoZVkM"
      },
      "source": [
        "# Load Pythia data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm9FCSIhakGV"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "generator = random.Random(42) ## deterministic results\n",
        "\n",
        "def cleanQuery(query, tableName):\n",
        "  pattern = re.compile(\"SELECT id, \", re.IGNORECASE)\n",
        "  query = pattern.sub(\"SELECT \", query)\n",
        "  pattern = re.compile(\"SELECT index, \", re.IGNORECASE)\n",
        "  query = pattern.sub(\"SELECT \", query)\n",
        "  query = query.replace(\"),\", \") ,\", 1)\n",
        "  indexStart = query.find(\"CONCAT(\")\n",
        "  indexEnd = query.find(\") ,\")\n",
        "  #if indexEnd == -1: indexEnd = query.find(\"),\")\n",
        "  if indexStart != -1 and indexEnd != -1:\n",
        "    query = query[:indexStart] + query[indexEnd+4:]\n",
        "  query = query.replace(tableName, \"dataframe\")\n",
        "  query = query.replace(\"\\n\", \" \")\n",
        "  query = query.replace(\"\\t\", \" \")\n",
        "  query = query.replace(\"  \", \" \").strip()\n",
        "  return query\n",
        "\n",
        "def loadSchema(fileSchema):\n",
        "  f = open(fileSchema)\n",
        "  dataset = json.load(f)\n",
        "  attributes = dataset['attributes']\n",
        "  tableName = dataset['datasetName']\n",
        "  attrNames = []\n",
        "  for attr in attributes:\n",
        "    attrNames.append(attr['name'])\n",
        "  return attrNames, tableName\n",
        "\n",
        "#def loadDataFromFile(file, schemaString, dropDuplicates = True):\n",
        "def loadDataFromFile(file, attrList, tableName, dropDuplicates = True, shuffleSchema = True):  \n",
        "  f = open(file)\n",
        "  data = json.load(f)\n",
        "  examples = []\n",
        "  sentencesSet = set()\n",
        "  querySet = set()\n",
        "  for example in data:\n",
        "      selectedData = pd.DataFrame.from_dict(example['dataframe'])\n",
        "      sentence = example['sentence']\n",
        "      if sentence.endswith(\".\") == False: \n",
        "        sentence += \".\"\n",
        "      label = example['matchType']\n",
        "      if label == \"uniform_true\": continue\n",
        "      query = example['a_query']\n",
        "      queryOrig = example['a_query']\n",
        "      query =  cleanQuery(query, tableName)\n",
        "      if attrList is None:\n",
        "        #dataframe = example['dataframe']\n",
        "        #schemaString = \"|\".join(list(selectedData.columns))\n",
        "        columns = example['dataframe'].keys()\n",
        "        schema = \"|\".join(list(columns))\n",
        "      else:\n",
        "        attr = attrList\n",
        "        if shuffleSchema:\n",
        "          generator.shuffle(attr)\n",
        "        columns = list(example['dataframe'].keys())\n",
        "        for i in range(0, 3):\n",
        "          a = attr[i]\n",
        "          if a not in columns and a.lower() != \"id\" and a.lower() != \"index\":\n",
        "            columns.append(a)\n",
        "        generator.shuffle(columns)\n",
        "        if \"id\" in columns: columns.remove(\"id\")\n",
        "        if \"index\" in columns: columns.remove(\"index\")\n",
        "        schema = \"|\".join(columns)\n",
        "      #schema = schema.replace(\"id|\", \"\", 1) ## replace id\n",
        "      sentence = sentence + \"schema:\" + schema\n",
        "      #if label != \"NO_AMBIGUITY\":\n",
        "      if label not in [\"NO_AMBIGUITY\"]:  \n",
        "        query = \"none\"\n",
        "      if dropDuplicates and sentence not in sentencesSet and queryOrig not in querySet:\n",
        "        pass\n",
        "        ##example = {\"sentence\": sentence, \"query\": query}\n",
        "        ##examples.append(example)\n",
        "        ##sentencesSet.add(sentence)\n",
        "        ##querySet.add(queryOrig)\n",
        "      if dropDuplicates and queryOrig not in querySet:\n",
        "        example = {\"sentence\": sentence, \"query\": query}\n",
        "        examples.append(example)\n",
        "        querySet.add(queryOrig)\n",
        "      if dropDuplicates == False:\n",
        "        example = {\"sentence\": sentence, \"query\": query}\n",
        "        examples.append(example)\n",
        "  return examples\n",
        "\n",
        "def loadData(folder):\n",
        "  files = [f for f in listdir(folder) if isfile(join(folder, f))]\n",
        "  examples = []\n",
        "  for f in files:\n",
        "    fileName = folder + f\n",
        "    exs = loadDataFromFile(fileName)\n",
        "    examples += exs\n",
        "  return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9IskmVPbhRW"
      },
      "outputs": [],
      "source": [
        "examples = []\n",
        "for sentenceFile, schemaFile in mappings:\n",
        "  print(\"Sentence File:\", sentenceFile)\n",
        "  print(\"Schema File:\", schemaFile)\n",
        "  schema = loadSchema(schemaFile)\n",
        "  examplesInFile = loadDataFromFile(sentenceFile, schema)\n",
        "  print(len(examplesInFile))\n",
        "  examples += examplesInFile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKK1AkndfMxl"
      },
      "outputs": [],
      "source": [
        "for ex in examples[0:20]:\n",
        "  sentence = ex['sentence']\n",
        "  expectedQ = ex['query']\n",
        "  predictedQ = get_sql(sentence)\n",
        "  print(\"Sentence:\", sentence)\n",
        "  print(\"Excpected:\", expectedQ)\n",
        "  print(\"Predicted:\", predictedQ)\n",
        "  print(\"*\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edSPF7AQATe8"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(examples, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yR1v3-8rKpzX"
      },
      "outputs": [],
      "source": [
        "def removeNone(dataset, percentageToRemove):\n",
        "  for example in list(dataset):\n",
        "    if example['query'] == \"none\" and generator.uniform(0, 1) >= percentageToRemove:\n",
        "      dataset.remove(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB-PlExpQb7L"
      },
      "outputs": [],
      "source": [
        "SENTENCES_FOLDER = \"MyDrive/nl2sql/\" ## DATA FOLDER. Change it. Dataset used available at: https://drive.google.com/drive/folders/1EQ7C4PXhK2xinutK2ONcM9LjO9kB9J9T?usp=sharing \n",
        "SCHEMA_FOLDER = \"MyDrive/nl2sql/schema/\"\n",
        "\n",
        "mappingsTrain = [\n",
        "            (SENTENCES_FOLDER+\"adults_sentence.json\",                     SCHEMA_FOLDER+\"adults.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"heart_2020_sentence.json\",                 SCHEMA_FOLDER+\"heart_2020.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"laptop_sentence.json\",                     SCHEMA_FOLDER+\"laptop.json\", 1.0), ##90\n",
        "            (SENTENCES_FOLDER+\"soccer_small_sentence.json\",               SCHEMA_FOLDER+\"soccer_small.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"mushroom_sentence.json\",                   SCHEMA_FOLDER+\"mushroom.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"superstore_sentence.json\",                 SCHEMA_FOLDER+\"superstore.json\", 1.0),\n",
        "            ##### FROM TEMPLATES \n",
        "            (SENTENCES_FOLDER+\"adults_template_sentence.json\",                     SCHEMA_FOLDER+\"adults.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"heart_2020_template_sentence.json\",                 SCHEMA_FOLDER+\"heart_2020.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"laptop_template_sentence.json\",                     SCHEMA_FOLDER+\"laptop.json\", 1.0), ##95\n",
        "            (SENTENCES_FOLDER+\"soccer_small_template_sentence.json\",               SCHEMA_FOLDER+\"soccer_small.json\", 1.0), ##95\n",
        "            (SENTENCES_FOLDER+\"mushroom_template_sentence.json\",                   SCHEMA_FOLDER+\"mushroom.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"superstore_template_sentence.json\",                 SCHEMA_FOLDER+\"superstore.json\", 1.0),\n",
        "            ]\n",
        "\n",
        "\n",
        "mappingsTest = [\n",
        "            (SENTENCES_FOLDER+\"abalone_sentence.json\",                    SCHEMA_FOLDER+\"abalone.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"basket_acronyms_sentence.json\",            SCHEMA_FOLDER+\"basket_acronyms.json\", 0.8),\n",
        "            (SENTENCES_FOLDER+\"iris_sentence.json\",                       SCHEMA_FOLDER+\"iris.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"wineqt_sentence.json\",                     SCHEMA_FOLDER+\"wineqt.json\", 1.0),\n",
        "            ##### FROM TEMPLATES \n",
        "            (SENTENCES_FOLDER+\"abalone_template_sentence.json\",                    SCHEMA_FOLDER+\"abalone.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"basket_acronyms_template_sentence.json\",            SCHEMA_FOLDER+\"basket_acronyms.json\", 0.9),\n",
        "            (SENTENCES_FOLDER+\"iris_template_sentence.json\",                       SCHEMA_FOLDER+\"iris.json\", 1.0),\n",
        "            (SENTENCES_FOLDER+\"basket_full_names_template_sentence.json\",            SCHEMA_FOLDER+\"basket_full_names.json\", 0.9),\n",
        "            ]\n",
        "\n",
        "shuffle = True\n",
        "train = []\n",
        "#mpTemp = []\n",
        "#mpTemp.append(mappingsTrain[-1])\n",
        "#mappingsTrain = mpTemp\n",
        "for sentenceFile, schemaFile, percentage in mappingsTrain:\n",
        "  print(\"Sentence File:\", sentenceFile)\n",
        "  print(\"Schema File:\", schemaFile)\n",
        "  attrNames, tableName = loadSchema(schemaFile)\n",
        "  #attrNames = None\n",
        "  examplesInFile = loadDataFromFile(sentenceFile, attrNames, tableName)\n",
        "  print(len(examplesInFile))\n",
        "  percentageRemove = 1.0 - percentage\n",
        "  if percentageRemove > 0:\n",
        "    removeNone(examplesInFile, percentageRemove)\n",
        "    print(\"Filtered dataset. Add: \", len(examplesInFile), \"examples\")\n",
        "  train += examplesInFile\n",
        "\n",
        "random.Random(42).shuffle(train)\n",
        "print(\"*******************************\")\n",
        "test = []\n",
        "for sentenceFile, schemaFile, percentage in mappingsTest:\n",
        "  print(\"Sentence File:\", sentenceFile)\n",
        "  print(\"Schema File:\", schemaFile)\n",
        "  attrNames, tableName = loadSchema(schemaFile)\n",
        "  #attrNames = None\n",
        "  examplesInFile = loadDataFromFile(sentenceFile, attrNames, tableName)\n",
        "  print(len(examplesInFile))\n",
        "  percentageRemove = 1.0 - percentage\n",
        "  if percentageRemove > 0:\n",
        "    removeNone(examplesInFile, percentageRemove)\n",
        "    print(\"Filtered dataset. Add: \", len(examplesInFile), \"examples\")\n",
        "  test += examplesInFile\n",
        "\n",
        "train, validation = train_test_split(train, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHw9_gyVAipy"
      },
      "outputs": [],
      "source": [
        "print(len(train))\n",
        "print(len(validation))\n",
        "print(len(test))\n",
        "print(train[0])\n",
        "print(validation[2])\n",
        "print(test[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## reduce the size of the train\n",
        "red = True\n",
        "if red:\n",
        "  train = train[0:300]\n",
        "print(len(train))"
      ],
      "metadata": {
        "id": "9Vfq6OlW5LOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRYRDxg4F0HS"
      },
      "outputs": [],
      "source": [
        "percentageToRemove = 0.4\n",
        "sampleTrain = False\n",
        "sampleTest = False\n",
        "\n",
        "if sampleTrain:\n",
        "  for example in list(train):\n",
        "    if example['query'] == \"none\" and generator.uniform(0, 1) >= percentageToRemove:\n",
        "      train.remove(example)\n",
        "\n",
        "if sampleTest:\n",
        "  for example in list(test):\n",
        "    if example['query'] == \"none\" and generator.uniform(0, 1) >= percentageToRemove:\n",
        "      test.remove(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d87xsfVbIHxE"
      },
      "outputs": [],
      "source": [
        "def toDict(dataset):\n",
        "  sentences = []\n",
        "  queries = []\n",
        "  for example in dataset:\n",
        "    sentences.append(example['sentence'])\n",
        "    queries.append(example['query'])\n",
        "  d = {\"sentence\": sentences, \"query\": queries}\n",
        "  return d\n",
        "\n",
        "train = train + validation ## comment if separated\n",
        "trainDataset = Dataset.from_dict(toDict(train))\n",
        "validationDataset = Dataset.from_dict(toDict(validation))\n",
        "testDataset = Dataset.from_dict(toDict(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs2xKYnDJY2H"
      },
      "outputs": [],
      "source": [
        "def format_dataset(example):\n",
        " return {'input': 'transalte to AMBSQL: ' + example['sentence'], 'target': example['query']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsQ_D_nvJsU-"
      },
      "outputs": [],
      "source": [
        "trainDataset = trainDataset.map(format_dataset, remove_columns=trainDataset.column_names)\n",
        "validationDataset = validationDataset.map(format_dataset, remove_columns=validationDataset.column_names)\n",
        "testDataset = testDataset.map(format_dataset, remove_columns=testDataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur2pxt9FKJrm"
      },
      "outputs": [],
      "source": [
        "print(trainDataset[0])\n",
        "print(validationDataset[0])\n",
        "print(testDataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P28R1UVO5LH0"
      },
      "outputs": [],
      "source": [
        "def distributionFromData(dataset):\n",
        "  freq = {\"query\": 0, \"none\": 0}\n",
        "  for i in range(0, dataset.__len__()):\n",
        "    example = dataset[i]\n",
        "    y = example['target']\n",
        "    if y == \"none\":\n",
        "      freq[\"none\"] += 1\n",
        "    else:\n",
        "      freq[\"query\"] += 1\n",
        "  return freq\n",
        "\n",
        "freqTrain = distributionFromData(trainDataset)\n",
        "freqTest = distributionFromData(testDataset)\n",
        "freqValidation = distributionFromData(validationDataset)\n",
        "print(freqTrain)\n",
        "print(freqValidation)\n",
        "print(freqTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAAMUdrIiTAe"
      },
      "outputs": [],
      "source": [
        "# map article and summary len to dict as well as if sample is longer than 512 tokens\n",
        "def map_to_length(x):\n",
        "  x[\"input_len\"] = len(tokenizer(x[\"input\"]).input_ids)\n",
        "  x[\"input_longer_256\"] = int(x[\"input_len\"] > 256)\n",
        "  x[\"input_longer_128\"] = int(x[\"input_len\"] > 128)\n",
        "  x[\"input_longer_64\"] = int(x[\"input_len\"] > 64)\n",
        "  x[\"out_len\"] = len(tokenizer(x[\"target\"]).input_ids)\n",
        "  x[\"out_longer_256\"] = int(x[\"out_len\"] > 256)\n",
        "  x[\"out_longer_128\"] = int(x[\"out_len\"] > 128)\n",
        "  x[\"out_longer_64\"] = int(x[\"out_len\"] > 64)\n",
        "  return x\n",
        "\n",
        "sample_size = 300\n",
        "data_stats = trainDataset.select(range(sample_size)).map(map_to_length, num_proc=4)\n",
        "\n",
        "def compute_and_print_stats(x):\n",
        "  if len(x[\"input_len\"]) == sample_size:\n",
        "    print(\n",
        "        \"Input Mean: {}, %-Input > 256:{},  %-Input > 128:{}, %-Input > 64:{} Output Mean:{}, %-Output > 256:{}, %-Output > 128:{}, %-Output > 64:{}\".format(\n",
        "            sum(x[\"input_len\"]) / sample_size,\n",
        "            sum(x[\"input_longer_256\"]) / sample_size,\n",
        "            sum(x[\"input_longer_128\"]) / sample_size,\n",
        "            sum(x[\"input_longer_64\"]) / sample_size,   \n",
        "            sum(x[\"out_len\"]) / sample_size,\n",
        "            sum(x[\"out_longer_256\"]) / sample_size,\n",
        "            sum(x[\"out_longer_128\"]) / sample_size,\n",
        "            sum(x[\"out_longer_64\"]) / sample_size,\n",
        "        )\n",
        "    )\n",
        "\n",
        "output = data_stats.map(\n",
        "  compute_and_print_stats, \n",
        "  batched=True,\n",
        "  batch_size=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lThMVoiA00GM"
      },
      "outputs": [],
      "source": [
        "# tokenize the examples\n",
        "\n",
        "INPUT_LENGTH = 128\n",
        "OUTPUT_LENGTH = 64\n",
        "\n",
        "def convert_to_features(example_batch):\n",
        "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], pad_to_max_length=True, max_length=INPUT_LENGTH)\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], pad_to_max_length=True, max_length=OUTPUT_LENGTH)\n",
        "\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'], \n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'labels': target_encodings['input_ids'],\n",
        "        'decoder_attention_mask': target_encodings['attention_mask']\n",
        "    }\n",
        "\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg0GW_4cKU5D"
      },
      "outputs": [],
      "source": [
        "train_data = trainDataset.map(convert_to_features, batched=True, remove_columns=trainDataset.column_names)\n",
        "validation_data = trainDataset.map(convert_to_features, batched=True, remove_columns=validationDataset.column_names)\n",
        "test_data = testDataset.map(convert_to_features, batched=True, remove_columns=testDataset.column_names)\n",
        "\n",
        "columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
        "\n",
        "train_data.set_format(type='torch', columns=columns)\n",
        "validation_data.set_format(type='torch', columns=columns)\n",
        "test_data.set_format(type='torch', columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3M7vTnXKi9D"
      },
      "outputs": [],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHS0TyAJBf7a"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w51ZPR2EEjWK"
      },
      "outputs": [],
      "source": [
        "# set training arguments - Feel free to adapt it\n",
        "\n",
        "MODEL_DIR = \"/content/t5-small-finetuned-amb-sql\"\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir= MODEL_DIR,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_steps=500,\n",
        "    save_strategy=\"epoch\",\n",
        "    #save_steps=1000,\n",
        "    #eval_steps=1000,\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=EPOCHS + 1,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False\n",
        "    #fp16=True, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ILNBTiUFIwg"
      },
      "outputs": [],
      "source": [
        "metric = load_metric(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd68HGU7FKqU"
      },
      "outputs": [],
      "source": [
        "from datasets.utils.file_utils import T\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    dec_labels = []\n",
        "    for dp in decoded_labels:\n",
        "      dec_labels.append(dp[0])\n",
        "    #print(decoded_preds)\n",
        "    #print(decoded_labels)\n",
        "    binaryLabels = [\"none\"]*len(dec_labels)\n",
        "    binaryLabels = np.array(binaryLabels) == np.array(dec_labels)\n",
        "    binaryPred = [\"none\"]*len(decoded_preds)\n",
        "    binaryPred = np.array(binaryPred) == np.array(decoded_preds)\n",
        "    #print(binaryLabels)\n",
        "    #print(binaryPred)\n",
        "    #print(np.unique(binaryLabels))\n",
        "    #print(np.unique(binaryPred))\n",
        "    precision = precision_score(binaryLabels, binaryPred)\n",
        "    recall = recall_score(binaryLabels, binaryPred)\n",
        "    f1 = f1_score(binaryLabels, binaryPred)\n",
        "    result[\"prec\"] = precision\n",
        "    result[\"rec\"] = recall\n",
        "    result[\"f1\"] = f1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix0gG-aaFsMG"
      },
      "outputs": [],
      "source": [
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "    #eval_dataset=validation_data,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL3hbjSIFxpY"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(eval_dataset=test_data.select(range(100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riDmH_EmF9eT"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvzrV2ceLEuZ"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(eval_dataset=test_data.select(range(40)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZePOdd9QWj8"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(eval_dataset=test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHbCQ8AmRE2w"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR+\"/checkpoint-552\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_3nMxJUQbGi"
      },
      "outputs": [],
      "source": [
        "def translate(text):\n",
        "    inputs = tokenizer(text, padding='longest', max_length=INPUT_LENGTH, return_tensors='pt')\n",
        "    input_ids = inputs.input_ids\n",
        "    attention_mask = inputs.attention_mask\n",
        "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=OUTPUT_LENGTH)\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsgcsJnBESfP"
      },
      "outputs": [],
      "source": [
        "testDataset = Dataset.from_dict(toDict(test))\n",
        "for i in range(0,200,1):\n",
        "#for i in range(150,230,1):  \n",
        "  print('translate to SQL: ' + testDataset[i]['sentence'])\n",
        "  print('Predict.: ' + translate('transalte to AMBSQL: ' + testDataset[i]['sentence']))\n",
        "  print('Expected: ' + testDataset[i]['query'])\n",
        "  print('=================================\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBJhXC3hKJbq"
      },
      "outputs": [],
      "source": [
        "#sentence = \"curry has 12 rebounds\"\n",
        "#sentence = \"curry has 12 field goals\"\n",
        "sentence = \"player had 12 fouls\"\n",
        "#sentence = \"player has 44 appearences\"\n",
        "#schema = \"schema: name|3 point goals|1 point score|field goal|3 point field goal|reb|dreb|foul|appearences\"\n",
        "schema = \"schema:field goal|3 point field goal|fouls\"\n",
        "\n",
        "#sentence = \"messi has 12 cards\"\n",
        "#schema = \"schema: player|goals|appearences|red cards|yellow cards|minutes\"\n",
        "predText = sentence + schema\n",
        "print('Predict.: ' + translate('transalte to AMBSQL: ' + predText))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBwfq8p7V7gE"
      },
      "outputs": [],
      "source": [
        "dir_path = MODEL_DIR\n",
        "shutil.rmtree(dir_path, ignore_errors=True)\n",
        "print(\"Deleted '%s' directory successfully\" % dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V4BNPlY8AlJ"
      },
      "outputs": [],
      "source": [
        "tokenizerBaseline = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
        "modelBaseline = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPiZbFMrwzGW"
      },
      "outputs": [],
      "source": [
        "def get_sql(query):\n",
        "  input_text = \"translate English to SQL: %s </s>\" % query\n",
        "  features = tokenizerBaseline([input_text], return_tensors='pt')\n",
        "\n",
        "  output = modelBaseline.generate(input_ids=features['input_ids'], \n",
        "               attention_mask=features['attention_mask'])\n",
        "  \n",
        "  return tokenizer.decode(output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKrYG_Q9w7ol"
      },
      "outputs": [],
      "source": [
        "testDataset = Dataset.from_dict(toDict(test))\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "tpList = []\n",
        "fpList = []\n",
        "tnList = []\n",
        "fnList = []\n",
        "for i in range(0,len(testDataset)):\n",
        "  query = testDataset[i]['sentence']\n",
        "  #predicted = get_sql(query)\n",
        "  #expected = testDataset[i]['query']\n",
        "  predicted = translate('transalte to AMBSQL: ' + testDataset[i]['sentence'])\n",
        "  expected = testDataset[i]['query']\n",
        "  sentence = testDataset[i]['sentence']\n",
        "  if predicted == \"none\" and expected == \"none\":\n",
        "    tp += 1\n",
        "    tpList.append((predicted, expected, sentence))\n",
        "  if predicted == \"none\" and expected != \"none\":\n",
        "    fp += 1\n",
        "    fpList.append((predicted, expected, sentence))\n",
        "  if predicted != \"none\" and expected == \"none\":\n",
        "    fn += 1\n",
        "    fnList.append((predicted, expected, sentence))\n",
        "  if predicted != \"none\" and expected != \"none\":\n",
        "    tn += 1\n",
        "    tnList.append((predicted, expected, sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6iS-083xezD"
      },
      "outputs": [],
      "source": [
        "if tp + fp == 0:\n",
        "  precision = 0.0\n",
        "else:\n",
        "  precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "if precision + recall == 0:\n",
        "  f1 = 0\n",
        "else:\n",
        "  f1 = (2 * precision * recall)/(precision + recall)\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "print(precision, recall, f1, accuracy,  sep=\"\\t\")\n",
        "print(\"TP:\", tp)\n",
        "print(\"FP:\", fp)\n",
        "print(\"TN:\", tn)\n",
        "print(\"FN:\", fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPBEwz03xjY8"
      },
      "outputs": [],
      "source": [
        "#eval_preds = []\n",
        "preds = []\n",
        "expecteds = []\n",
        "for predicted, expected, sentence in tnList:\n",
        "  pred = predicted.replace(\"<pad> \", \"\")\n",
        "  #print(\"Pred:\", pred)\n",
        "  #print(\"Expe:\", expected)\n",
        "  #print(\"Sent:\", sentence)\n",
        "  #print('=================================\\n')\n",
        "  preds.append(pred)\n",
        "  expecteds.append(expected)\n",
        "  #eval_preds.append((pred, expected))\n",
        "\n",
        "preds, expecteds = postprocess_text(preds, expecteds)\n",
        "resultBleu = metric.compute(predictions=preds, references=expecteds)\n",
        "print(resultBleu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMysTzanIcGu"
      },
      "source": [
        "## FINE TUNE A BIGGER MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW6XjodF0CfR"
      },
      "outputs": [],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oL4-kUcIiQy"
      },
      "outputs": [],
      "source": [
        "! pip install -q transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBwvo9fdIpQK"
      },
      "outputs": [],
      "source": [
        "CKPT = 't5-large'\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "tokenizer = AutoTokenizer.from_pretrained(CKPT)\n",
        "model = T5ForConditionalGeneration.from_pretrained(CKPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldwBFK4XIzBx"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds_1 = load_dataset('wikisql')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-pBQIF7I7RF"
      },
      "outputs": [],
      "source": [
        "def format_dataset_1(example):\n",
        " return {'input': 'translate to SQL: ' + example['question'], 'target': example['sql']['human_readable']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENrCK4BTI7sf"
      },
      "outputs": [],
      "source": [
        "ds_1 = ds_1.map(format_dataset_1, remove_columns=ds_1['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCUcnmizI-vR"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "train_data = concatenate_datasets([ds_1['train'], ds_1['validation']]).shuffle(seed=42)\n",
        "test_data = concatenate_datasets([ds_1['test']]).shuffle(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i7ibtvdJMXq"
      },
      "outputs": [],
      "source": [
        "# map article and summary len to dict as well as if sample is longer than 512 tokens\n",
        "def map_to_length(x):\n",
        "  x[\"input_len\"] = len(tokenizer(x[\"input\"]).input_ids)\n",
        "  x[\"input_longer_256\"] = int(x[\"input_len\"] > 256)\n",
        "  x[\"input_longer_128\"] = int(x[\"input_len\"] > 128)\n",
        "  x[\"input_longer_64\"] = int(x[\"input_len\"] > 64)\n",
        "  x[\"out_len\"] = len(tokenizer(x[\"target\"]).input_ids)\n",
        "  x[\"out_longer_256\"] = int(x[\"out_len\"] > 256)\n",
        "  x[\"out_longer_128\"] = int(x[\"out_len\"] > 128)\n",
        "  x[\"out_longer_64\"] = int(x[\"out_len\"] > 64)\n",
        "  return x\n",
        "\n",
        "sample_size = 10000\n",
        "data_stats = train_data.select(range(sample_size)).map(map_to_length, num_proc=4)\n",
        "\n",
        "def compute_and_print_stats(x):\n",
        "  if len(x[\"input_len\"]) == sample_size:\n",
        "    print(\n",
        "        \"Input Mean: {}, %-Input > 256:{},  %-Input > 128:{}, %-Input > 64:{} Output Mean:{}, %-Output > 256:{}, %-Output > 128:{}, %-Output > 64:{}\".format(\n",
        "            sum(x[\"input_len\"]) / sample_size,\n",
        "            sum(x[\"input_longer_256\"]) / sample_size,\n",
        "            sum(x[\"input_longer_128\"]) / sample_size,\n",
        "            sum(x[\"input_longer_64\"]) / sample_size,   \n",
        "            sum(x[\"out_len\"]) / sample_size,\n",
        "            sum(x[\"out_longer_256\"]) / sample_size,\n",
        "            sum(x[\"out_longer_128\"]) / sample_size,\n",
        "            sum(x[\"out_longer_64\"]) / sample_size,\n",
        "        )\n",
        "    )\n",
        "\n",
        "output = data_stats.map(\n",
        "  compute_and_print_stats, \n",
        "  batched=True,\n",
        "  batch_size=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhVviSZSJQ-o"
      },
      "outputs": [],
      "source": [
        "# tokenize the examples\n",
        "INPUT_ENCODINGS_SIZE_T5_LARGE = 64\n",
        "TARGET_ENCODINGS_SIZE_T5_LARGE = 64\n",
        "def convert_to_features(example_batch):\n",
        "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], pad_to_max_length=True, max_length=INPUT_ENCODINGS_SIZE_T5_LARGE)\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], pad_to_max_length=True, max_length=TARGET_ENCODINGS_SIZE_T5_LARGE)\n",
        "\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'], \n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'labels': target_encodings['input_ids'],\n",
        "        'decoder_attention_mask': target_encodings['attention_mask']\n",
        "    }\n",
        "\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG21S_jQJpA5"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.map(convert_to_features, batched=True, remove_columns=train_data.column_names)\n",
        "test_data = test_data.map(convert_to_features, batched=True, remove_columns=test_data.column_names)\n",
        "\n",
        "columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
        "\n",
        "train_data.set_format(type='torch', columns=columns)\n",
        "test_data.set_format(type='torch', columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkdqaOGOJraU"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62i1l400JvH-"
      },
      "outputs": [],
      "source": [
        "# set training arguments - Feel free to adapt it\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 8\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/t5-large-finetuned-wikisql-nl-sql\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_steps=500,\n",
        "    save_strategy=\"epoch\",\n",
        "    #save_steps=1000,\n",
        "    #eval_steps=1000,\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False\n",
        "    #fp16=True, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UL5SGmDcJ-ex"
      },
      "outputs": [],
      "source": [
        "! pip install -q sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5HUyLvIKARB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDzAWNr_KB_a"
      },
      "outputs": [],
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxr-AycyKD5D"
      },
      "outputs": [],
      "source": [
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3emGW8JPKcXk"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ji8OKLdMzVc"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrWI0NjWKfxZ"
      },
      "outputs": [],
      "source": [
        "!gsutil cp -r '/content/t5-large-finetuned-wikisql-nl-sql/' 'gs://pythia_t5/nl-sql/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-PXTuhRIMJh"
      },
      "source": [
        "## Code for automatically click connect (run on console cmd+alt+i)\n",
        "```\n",
        "function KeepClicking(){\n",
        "console.log(\"Clicking\");\n",
        "document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(KeepClicking,60000)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5kVmHKkSw73"
      },
      "outputs": [],
      "source": [
        "#!gsutil cp -r '/content/t5-large-finetuned-wikisql-nl-sql/' 'gs://pythia_t5/nl-sql/'\n",
        "!gsutil cp -r 'gs://pythia_t5/nl-sql/t5-large-finetuned-wikisql-nl-sql/checkpoint-8097/' '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNzf6iXxTD8z"
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = \"/content/checkpoint-8097/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqavV30lTsIK"
      },
      "outputs": [],
      "source": [
        "#model = AutoModelWithLMHead.from_pretrained(MODEL_DIR)\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wMysTzanIcGu",
        "k-PXTuhRIMJh"
      ],
      "machine_shape": "hm",
      "name": "NL2SQL-Exp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}